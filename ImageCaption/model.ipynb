{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import gzip\n",
    "import copy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import paddle.v2 as paddle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet 50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIM=224*224*3\n",
    "DICT_DIM=10000\n",
    "image = paddle.layer.data(name=\"image\", type=paddle.data_type.dense_vector(DATA_DIM))\n",
    "target = paddle.layer.data(name=\"target\", type=paddle.data_type.integer_value_sequence(DICT_DIM))\n",
    "label = paddle.layer.data(name=\"label\", type=paddle.data_type.integer_value_sequence(DICT_DIM))\n",
    "paddle.init(use_gpu=False, trainer_count=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn_layer(input,\n",
    "                  ch_out,\n",
    "                  filter_size,\n",
    "                  stride,\n",
    "                  padding,\n",
    "                  active_type=paddle.activation.Relu(),\n",
    "                  ch_in=None):\n",
    "    tmp = paddle.layer.img_conv(\n",
    "        input=input,\n",
    "        filter_size=filter_size,\n",
    "        num_channels=ch_in,\n",
    "        num_filters=ch_out,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        act=paddle.activation.Linear(),\n",
    "        bias_attr=False)\n",
    "    return paddle.layer.batch_norm(input=tmp, act=active_type)\n",
    "\n",
    "\n",
    "def shortcut(input, ch_out, stride):\n",
    "    if input.num_filters != ch_out:\n",
    "        return conv_bn_layer(input, ch_out, 1, stride, 0,\n",
    "                             paddle.activation.Linear())\n",
    "    else:\n",
    "        return input\n",
    "\n",
    "\n",
    "def basicblock(input, ch_out, stride):\n",
    "    short = shortcut(input, ch_out, stride)\n",
    "    conv1 = conv_bn_layer(input, ch_out, 3, stride, 1)\n",
    "    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1, paddle.activation.Linear())\n",
    "    return paddle.layer.addto(\n",
    "        input=[short, conv2], act=paddle.activation.Relu())\n",
    "\n",
    "\n",
    "def bottleneck(input, ch_out, stride):\n",
    "    short = shortcut(input, ch_out * 4, stride)\n",
    "    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n",
    "    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n",
    "    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0,\n",
    "                          paddle.activation.Linear())\n",
    "    return paddle.layer.addto(\n",
    "        input=[short, conv3], act=paddle.activation.Relu())\n",
    "\n",
    "\n",
    "def layer_warp(block_func, input, ch_out, count, stride):\n",
    "    conv = block_func(input, ch_out, stride)\n",
    "    for i in range(1, count):\n",
    "        conv = block_func(conv, ch_out, 1)\n",
    "    return conv\n",
    "\n",
    "\n",
    "def resnet_imagenet(input, depth=50):\n",
    "    cfg = {\n",
    "        18: ([2, 2, 2, 1], basicblock),\n",
    "        34: ([3, 4, 6, 3], basicblock),\n",
    "        50: ([3, 4, 6, 3], bottleneck),\n",
    "        101: ([3, 4, 23, 3], bottleneck),\n",
    "        152: ([3, 8, 36, 3], bottleneck)\n",
    "    }\n",
    "    stages, block_func = cfg[depth]\n",
    "    conv1 = conv_bn_layer(\n",
    "        input, ch_in=3, ch_out=64, filter_size=7, stride=2, padding=3)\n",
    "    pool1 = paddle.layer.img_pool(input=conv1, pool_size=3, stride=2)\n",
    "    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n",
    "    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n",
    "    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n",
    "    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n",
    "    pool2 = paddle.layer.img_pool(\n",
    "        input=res4, pool_size=7, stride=1, pool_type=paddle.pooling.Avg())\n",
    "    output = paddle.layer.fc(pool2, act=paddle.activation.Softmax(), size=1000)\n",
    "    return pool2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(features, target, dict_dim, embed_size=512, label=None, is_train=True):\n",
    "    \n",
    "    encoded_features = paddle.layer.fc(\n",
    "        input=features,\n",
    "        size=512,\n",
    "        act=paddle.activation.Relu(),\n",
    "        name='encoded_features'\n",
    "    )\n",
    "        \n",
    "    input_emb = paddle.layer.embedding(target, size=embed_size, name='embedding')\n",
    "    input_emb = paddle.layer.fc(input=input_emb, size=512*3)\n",
    "    \n",
    "    grus = paddle.networks.gru_group(\n",
    "        input=[input_emb],\n",
    "        memory_boot=encoded_features,\n",
    "        size=512,\n",
    "        name='gru_group_layer'\n",
    "    )\n",
    "    # input_ = paddle.layer.concat(input=inputs)\n",
    "    \n",
    "#     rnn = paddle.networks.bidirectional_gru(input=inputs, size=1024, return_seq=True)\n",
    "    \n",
    "#     for i in xrange(num_layers-1):\n",
    "#         rnn = paddle.networks.simple_lstm(input=rnn, size=512)\n",
    "    \n",
    "    output = paddle.layer.fc(input=grus, size=dict_dim, act=paddle.activation.Softmax())\n",
    "    \n",
    "    if is_train:\n",
    "        cost = paddle.layer.classification_cost(input=output, label=label)\n",
    "        return cost\n",
    "    else:\n",
    "        last_word = paddle.layer.last_seq(input=output)\n",
    "        return last_word    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_caption_net(input_images, target, label, dict_dim):\n",
    "    \n",
    "    encoder_ = resnet_imagenet(input_images)\n",
    "    cost = decoder(features=encoder_, target=target, label=label, dict_dim=dict_dim)\n",
    "    \n",
    "    return cost\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_handler(event):\n",
    "    if isinstance(event, paddle.event.EndIteration):\n",
    "        if event.batch_id % 1 == 0:\n",
    "            print \"\\nPass %d, Batch %d, Cost %f, %s\" % (\n",
    "                event.pass_id, event.batch_id, event.cost, event.metrics)\n",
    "    if isinstance(event, paddle.event.EndPass):\n",
    "        with gzip.open('params_pass_%d.tar.gz' % event.pass_id, 'w') as f:\n",
    "            parameters.to_tar(f)\n",
    "\n",
    "        result = trainer.test(reader=test_reader)\n",
    "        print \"\\nTest with Pass %d, %s\" % (event.pass_id, result.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_DIM=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-01-31 14:21:49,397 layers.py:2689] output for __conv_0__: c = 64, h = 112, w = 112, size = 802816\n",
      "[INFO 2018-01-31 14:21:49,402 layers.py:3251] output for __batch_norm_0__: c = 64, h = 112, w = 112, size = 802816\n",
      "[INFO 2018-01-31 14:21:49,410 layers.py:2829] output for __pool_0__: c = 64, h = 56, w = 56, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,417 layers.py:2689] output for __conv_1__: c = 256, h = 56, w = 56, size = 802816\n",
      "[INFO 2018-01-31 14:21:49,423 layers.py:3251] output for __batch_norm_1__: c = 256, h = 56, w = 56, size = 802816\n",
      "[INFO 2018-01-31 14:21:49,432 layers.py:2689] output for __conv_2__: c = 64, h = 56, w = 56, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,439 layers.py:3251] output for __batch_norm_2__: c = 64, h = 56, w = 56, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,445 layers.py:2689] output for __conv_3__: c = 64, h = 56, w = 56, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,452 layers.py:3251] output for __batch_norm_3__: c = 64, h = 56, w = 56, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,461 layers.py:2689] output for __conv_4__: c = 256, h = 56, w = 56, size = 802816\n",
      "[INFO 2018-01-31 14:21:49,482 layers.py:3251] output for __batch_norm_4__: c = 256, h = 56, w = 56, size = 802816\n",
      "[INFO 2018-01-31 14:21:49,509 layers.py:2689] output for __conv_5__: c = 64, h = 56, w = 56, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,513 layers.py:3251] output for __batch_norm_5__: c = 64, h = 56, w = 56, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,517 layers.py:2689] output for __conv_6__: c = 64, h = 56, w = 56, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,524 layers.py:3251] output for __batch_norm_6__: c = 64, h = 56, w = 56, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,530 layers.py:2689] output for __conv_7__: c = 256, h = 56, w = 56, size = 802816\n",
      "[INFO 2018-01-31 14:21:49,534 layers.py:3251] output for __batch_norm_7__: c = 256, h = 56, w = 56, size = 802816\n",
      "[INFO 2018-01-31 14:21:49,543 layers.py:2689] output for __conv_8__: c = 64, h = 56, w = 56, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,546 layers.py:3251] output for __batch_norm_8__: c = 64, h = 56, w = 56, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,549 layers.py:2689] output for __conv_9__: c = 64, h = 56, w = 56, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,556 layers.py:3251] output for __batch_norm_9__: c = 64, h = 56, w = 56, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,561 layers.py:2689] output for __conv_10__: c = 256, h = 56, w = 56, size = 802816\n",
      "[INFO 2018-01-31 14:21:49,565 layers.py:3251] output for __batch_norm_10__: c = 256, h = 56, w = 56, size = 802816\n",
      "[INFO 2018-01-31 14:21:49,571 layers.py:2689] output for __conv_11__: c = 512, h = 28, w = 28, size = 401408\n",
      "[INFO 2018-01-31 14:21:49,579 layers.py:3251] output for __batch_norm_11__: c = 512, h = 28, w = 28, size = 401408\n",
      "[INFO 2018-01-31 14:21:49,583 layers.py:2689] output for __conv_12__: c = 128, h = 28, w = 28, size = 100352\n",
      "[INFO 2018-01-31 14:21:49,588 layers.py:3251] output for __batch_norm_12__: c = 128, h = 28, w = 28, size = 100352\n",
      "[INFO 2018-01-31 14:21:49,593 layers.py:2689] output for __conv_13__: c = 128, h = 28, w = 28, size = 100352\n",
      "[INFO 2018-01-31 14:21:49,596 layers.py:3251] output for __batch_norm_13__: c = 128, h = 28, w = 28, size = 100352\n",
      "[INFO 2018-01-31 14:21:49,601 layers.py:2689] output for __conv_14__: c = 512, h = 28, w = 28, size = 401408\n",
      "[INFO 2018-01-31 14:21:49,607 layers.py:3251] output for __batch_norm_14__: c = 512, h = 28, w = 28, size = 401408\n",
      "[INFO 2018-01-31 14:21:49,613 layers.py:2689] output for __conv_15__: c = 128, h = 28, w = 28, size = 100352\n",
      "[INFO 2018-01-31 14:21:49,616 layers.py:3251] output for __batch_norm_15__: c = 128, h = 28, w = 28, size = 100352\n",
      "[INFO 2018-01-31 14:21:49,625 layers.py:2689] output for __conv_16__: c = 128, h = 28, w = 28, size = 100352\n",
      "[INFO 2018-01-31 14:21:49,629 layers.py:3251] output for __batch_norm_16__: c = 128, h = 28, w = 28, size = 100352\n",
      "[INFO 2018-01-31 14:21:49,632 layers.py:2689] output for __conv_17__: c = 512, h = 28, w = 28, size = 401408\n",
      "[INFO 2018-01-31 14:21:49,637 layers.py:3251] output for __batch_norm_17__: c = 512, h = 28, w = 28, size = 401408\n",
      "[INFO 2018-01-31 14:21:49,644 layers.py:2689] output for __conv_18__: c = 128, h = 28, w = 28, size = 100352\n",
      "[INFO 2018-01-31 14:21:49,649 layers.py:3251] output for __batch_norm_18__: c = 128, h = 28, w = 28, size = 100352\n",
      "[INFO 2018-01-31 14:21:49,656 layers.py:2689] output for __conv_19__: c = 128, h = 28, w = 28, size = 100352\n",
      "[INFO 2018-01-31 14:21:49,660 layers.py:3251] output for __batch_norm_19__: c = 128, h = 28, w = 28, size = 100352\n",
      "[INFO 2018-01-31 14:21:49,664 layers.py:2689] output for __conv_20__: c = 512, h = 28, w = 28, size = 401408\n",
      "[INFO 2018-01-31 14:21:49,668 layers.py:3251] output for __batch_norm_20__: c = 512, h = 28, w = 28, size = 401408\n",
      "[INFO 2018-01-31 14:21:49,675 layers.py:2689] output for __conv_21__: c = 128, h = 28, w = 28, size = 100352\n",
      "[INFO 2018-01-31 14:21:49,680 layers.py:3251] output for __batch_norm_21__: c = 128, h = 28, w = 28, size = 100352\n",
      "[INFO 2018-01-31 14:21:49,684 layers.py:2689] output for __conv_22__: c = 128, h = 28, w = 28, size = 100352\n",
      "[INFO 2018-01-31 14:21:49,690 layers.py:3251] output for __batch_norm_22__: c = 128, h = 28, w = 28, size = 100352\n",
      "[INFO 2018-01-31 14:21:49,699 layers.py:2689] output for __conv_23__: c = 512, h = 28, w = 28, size = 401408\n",
      "[INFO 2018-01-31 14:21:49,703 layers.py:3251] output for __batch_norm_23__: c = 512, h = 28, w = 28, size = 401408\n",
      "[INFO 2018-01-31 14:21:49,711 layers.py:2689] output for __conv_24__: c = 1024, h = 14, w = 14, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,715 layers.py:3251] output for __batch_norm_24__: c = 1024, h = 14, w = 14, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,719 layers.py:2689] output for __conv_25__: c = 256, h = 14, w = 14, size = 50176\n",
      "[INFO 2018-01-31 14:21:49,726 layers.py:3251] output for __batch_norm_25__: c = 256, h = 14, w = 14, size = 50176\n",
      "[INFO 2018-01-31 14:21:49,730 layers.py:2689] output for __conv_26__: c = 256, h = 14, w = 14, size = 50176\n",
      "[INFO 2018-01-31 14:21:49,737 layers.py:3251] output for __batch_norm_26__: c = 256, h = 14, w = 14, size = 50176\n",
      "[INFO 2018-01-31 14:21:49,743 layers.py:2689] output for __conv_27__: c = 1024, h = 14, w = 14, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,746 layers.py:3251] output for __batch_norm_27__: c = 1024, h = 14, w = 14, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,752 layers.py:2689] output for __conv_28__: c = 256, h = 14, w = 14, size = 50176\n",
      "[INFO 2018-01-31 14:21:49,756 layers.py:3251] output for __batch_norm_28__: c = 256, h = 14, w = 14, size = 50176\n",
      "[INFO 2018-01-31 14:21:49,761 layers.py:2689] output for __conv_29__: c = 256, h = 14, w = 14, size = 50176\n",
      "[INFO 2018-01-31 14:21:49,765 layers.py:3251] output for __batch_norm_29__: c = 256, h = 14, w = 14, size = 50176\n",
      "[INFO 2018-01-31 14:21:49,770 layers.py:2689] output for __conv_30__: c = 1024, h = 14, w = 14, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,777 layers.py:3251] output for __batch_norm_30__: c = 1024, h = 14, w = 14, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,781 layers.py:2689] output for __conv_31__: c = 256, h = 14, w = 14, size = 50176\n",
      "[INFO 2018-01-31 14:21:49,786 layers.py:3251] output for __batch_norm_31__: c = 256, h = 14, w = 14, size = 50176\n",
      "[INFO 2018-01-31 14:21:49,794 layers.py:2689] output for __conv_32__: c = 256, h = 14, w = 14, size = 50176\n",
      "[INFO 2018-01-31 14:21:49,798 layers.py:3251] output for __batch_norm_32__: c = 256, h = 14, w = 14, size = 50176\n",
      "[INFO 2018-01-31 14:21:49,802 layers.py:2689] output for __conv_33__: c = 1024, h = 14, w = 14, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,805 layers.py:3251] output for __batch_norm_33__: c = 1024, h = 14, w = 14, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,811 layers.py:2689] output for __conv_34__: c = 256, h = 14, w = 14, size = 50176\n",
      "[INFO 2018-01-31 14:21:49,816 layers.py:3251] output for __batch_norm_34__: c = 256, h = 14, w = 14, size = 50176\n",
      "[INFO 2018-01-31 14:21:49,821 layers.py:2689] output for __conv_35__: c = 256, h = 14, w = 14, size = 50176\n",
      "[INFO 2018-01-31 14:21:49,826 layers.py:3251] output for __batch_norm_35__: c = 256, h = 14, w = 14, size = 50176\n",
      "[INFO 2018-01-31 14:21:49,830 layers.py:2689] output for __conv_36__: c = 1024, h = 14, w = 14, size = 200704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-01-31 14:21:49,835 layers.py:3251] output for __batch_norm_36__: c = 1024, h = 14, w = 14, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,840 layers.py:2689] output for __conv_37__: c = 256, h = 14, w = 14, size = 50176\n",
      "[INFO 2018-01-31 14:21:49,846 layers.py:3251] output for __batch_norm_37__: c = 256, h = 14, w = 14, size = 50176\n",
      "[INFO 2018-01-31 14:21:49,850 layers.py:2689] output for __conv_38__: c = 256, h = 14, w = 14, size = 50176\n",
      "[INFO 2018-01-31 14:21:49,855 layers.py:3251] output for __batch_norm_38__: c = 256, h = 14, w = 14, size = 50176\n",
      "[INFO 2018-01-31 14:21:49,861 layers.py:2689] output for __conv_39__: c = 1024, h = 14, w = 14, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,865 layers.py:3251] output for __batch_norm_39__: c = 1024, h = 14, w = 14, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,870 layers.py:2689] output for __conv_40__: c = 256, h = 14, w = 14, size = 50176\n",
      "[INFO 2018-01-31 14:21:49,878 layers.py:3251] output for __batch_norm_40__: c = 256, h = 14, w = 14, size = 50176\n",
      "[INFO 2018-01-31 14:21:49,882 layers.py:2689] output for __conv_41__: c = 256, h = 14, w = 14, size = 50176\n",
      "[INFO 2018-01-31 14:21:49,886 layers.py:3251] output for __batch_norm_41__: c = 256, h = 14, w = 14, size = 50176\n",
      "[INFO 2018-01-31 14:21:49,892 layers.py:2689] output for __conv_42__: c = 1024, h = 14, w = 14, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,896 layers.py:3251] output for __batch_norm_42__: c = 1024, h = 14, w = 14, size = 200704\n",
      "[INFO 2018-01-31 14:21:49,902 layers.py:2689] output for __conv_43__: c = 2048, h = 7, w = 7, size = 100352\n",
      "[INFO 2018-01-31 14:21:49,909 layers.py:3251] output for __batch_norm_43__: c = 2048, h = 7, w = 7, size = 100352\n",
      "[INFO 2018-01-31 14:21:49,915 layers.py:2689] output for __conv_44__: c = 512, h = 7, w = 7, size = 25088\n",
      "[INFO 2018-01-31 14:21:49,920 layers.py:3251] output for __batch_norm_44__: c = 512, h = 7, w = 7, size = 25088\n",
      "[INFO 2018-01-31 14:21:49,927 layers.py:2689] output for __conv_45__: c = 512, h = 7, w = 7, size = 25088\n",
      "[INFO 2018-01-31 14:21:49,931 layers.py:3251] output for __batch_norm_45__: c = 512, h = 7, w = 7, size = 25088\n",
      "[INFO 2018-01-31 14:21:49,934 layers.py:2689] output for __conv_46__: c = 2048, h = 7, w = 7, size = 100352\n",
      "[INFO 2018-01-31 14:21:49,940 layers.py:3251] output for __batch_norm_46__: c = 2048, h = 7, w = 7, size = 100352\n",
      "[INFO 2018-01-31 14:21:49,948 layers.py:2689] output for __conv_47__: c = 512, h = 7, w = 7, size = 25088\n",
      "[INFO 2018-01-31 14:21:49,952 layers.py:3251] output for __batch_norm_47__: c = 512, h = 7, w = 7, size = 25088\n",
      "[INFO 2018-01-31 14:21:49,960 layers.py:2689] output for __conv_48__: c = 512, h = 7, w = 7, size = 25088\n",
      "[INFO 2018-01-31 14:21:49,964 layers.py:3251] output for __batch_norm_48__: c = 512, h = 7, w = 7, size = 25088\n",
      "[INFO 2018-01-31 14:21:49,968 layers.py:2689] output for __conv_49__: c = 2048, h = 7, w = 7, size = 100352\n",
      "[INFO 2018-01-31 14:21:49,977 layers.py:3251] output for __batch_norm_49__: c = 2048, h = 7, w = 7, size = 100352\n",
      "[INFO 2018-01-31 14:21:49,982 layers.py:2689] output for __conv_50__: c = 512, h = 7, w = 7, size = 25088\n",
      "[INFO 2018-01-31 14:21:49,987 layers.py:3251] output for __batch_norm_50__: c = 512, h = 7, w = 7, size = 25088\n",
      "[INFO 2018-01-31 14:21:49,993 layers.py:2689] output for __conv_51__: c = 512, h = 7, w = 7, size = 25088\n",
      "[INFO 2018-01-31 14:21:49,997 layers.py:3251] output for __batch_norm_51__: c = 512, h = 7, w = 7, size = 25088\n",
      "[INFO 2018-01-31 14:21:50,001 layers.py:2689] output for __conv_52__: c = 2048, h = 7, w = 7, size = 100352\n",
      "[INFO 2018-01-31 14:21:50,005 layers.py:3251] output for __batch_norm_52__: c = 2048, h = 7, w = 7, size = 100352\n",
      "[INFO 2018-01-31 14:21:50,012 layers.py:2829] output for __pool_1__: c = 2048, h = 1, w = 1, size = 2048\n"
     ]
    }
   ],
   "source": [
    "cost = train_caption_net(dict_dim=DICT_DIM, target=target, label=label, input_images=image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optimizer = paddle.optimizer.Adam(\n",
    "    learning_rate=1e-4,\n",
    "    regularization=paddle.optimizer.L2Regularization(rate=8e-4),\n",
    "    model_average=paddle.optimizer.ModelAverage(average_window=0.5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0  917 3658 6736 3379 1297 1595 7641 8177 7995 7563]\n",
      "[ 917 3658 6736 3379 1297 1595 7641 8177 7995 7563    1]\n"
     ]
    }
   ],
   "source": [
    "label = np.random.randint(2,10000, 11)\n",
    "label[-1] = 1\n",
    "target = np.zeros(11).astype('int')\n",
    "target[1:11] = label[:-1]\n",
    "target[0] = 0\n",
    "print(target)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reader():\n",
    "    \n",
    "    def reader():\n",
    "        \n",
    "        for i in xrange(10):\n",
    "        \n",
    "            image = np.random.randn(224*224*3) * 255\n",
    "            label = np.random.randint(2,10000, 11)\n",
    "            label[-1] = 1\n",
    "            target = np.zeros(11).astype('int')\n",
    "            target[1:11] = label[:-1]\n",
    "            target[0] = 0\n",
    "\n",
    "            yield image, target, label\n",
    "    return reader\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reader = create_reader()\n",
    "train_batch = paddle.batch(reader=paddle.reader.shuffle(train_reader, buf_size=10),batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeding = {'image':0, 'label':2, 'target':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = paddle.parameters.create(cost)\n",
    "parameters.init_from_tar(gzip.open('params/Paddle_ResNet50.tar.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = paddle.trainer.SGD(cost=cost,parameters=parameters,update_equation=adam_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pass 0, Batch 0, Cost 101.391457, {'classification_error_evaluator': 1.0}\n",
      "\n",
      "Pass 0, Batch 1, Cost 101.426231, {'classification_error_evaluator': 1.0}\n",
      "\n",
      "Pass 0, Batch 2, Cost 101.229340, {'classification_error_evaluator': 1.0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c9f8cb56beb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevent_handler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevent_handler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeeding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeeding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_passes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Python/2.7/site-packages/paddle/v2/trainer.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, reader, num_passes, event_handler, feeding)\u001b[0m\n\u001b[1;32m    199\u001b[0m                     \u001b[0mpass_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                     \u001b[0mevaluator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpass_evaluator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m                     gm=self.__gradient_machine__))\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__gradient_machine__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-90c8079e0ea8>\u001b[0m in \u001b[0;36mevent_handler\u001b[0;34m(event)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEndPass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'params_pass_%d.tar.gz'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpass_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_reader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/paddle/v2/parameters.pyc\u001b[0m in \u001b[0;36mto_tar\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m             \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__param_conf__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/tarfile.pyc\u001b[0m in \u001b[0;36maddfile\u001b[0;34m(self, tarinfo, fileobj)\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# If there's data to follow, append it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2045\u001b[0;31m             \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2046\u001b[0m             \u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremainder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBLOCKSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremainder\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/tarfile.pyc\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(src, dst, length)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mBUFSIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"end of file reached\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mdst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mremainder\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/gzip.pyc\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrc32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xffffffffL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(reader=train_batch,event_handler=event_handler,feeding=feeding,num_passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
